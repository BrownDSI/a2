{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2b Part 1: Web Scraping\n",
    "\n",
    "While web APIs and downloadable CSV files are convenient, a lot of online data is only available embedded in web pages.  Accessing these data using custom web scraping code is the only way one can collect it. For example, Billboard.com, the data-dense site we are going to scrape today using __beautiful soup__, does not have an official API.  In order to access this data, the raw HTML needs to be downloaded and processed to extract fields of interest.\n",
    "\n",
    "## Task 0\n",
    "Open the following in separate tabs (or desktops):\n",
    "\n",
    "* [requests](http://docs.python-requests.org/en/master/user/quickstart/)\n",
    "* [beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag)\n",
    "* [billboard](http://www.billboard.com/charts/hot-100])\n",
    "\n",
    "Today, we will be using two libraries: __requests__ and __beautiful soup__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1\n",
    "__Using the python _requests_ library, send a HTTP GET request to http://www.billboard.com/charts/hot-100 and then print the text of the response. The _requests_ user guide is available [here](http://docs.python-requests.org/en/master/user/quickstart/).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a lot of text beginning with something like the following:\n",
    "\n",
    "    <!doctype html>\n",
    "    <html class=\"\" lang=\"\">\n",
    "    <head>\n",
    "    ...\n",
    "\n",
    "then you have obtained the HTML from billboard that we will want to parse today. \n",
    "\n",
    "The python package Beautiful Soup converts HTML pages into a tree representation that can be easily navigated.\n",
    "Let's use __beautiful soup__ to more easily navigate the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beautiful soup allows us to treat HTML as a tree\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to navigate HTML as tree we need to understand what HTML is. Below a basic intro to HTML.  Additional information is available from [Mozilla](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics):\n",
    "***\n",
    "### So what is HTML, really?\n",
    "HTML consists of a series of elements, which you use to enclose, or wrap, different parts of the content to cause it to render (appear) in a certain way, or act a certain way, when viewed in a browser. Enclosing tags can make a word or an image a hyperlink to somewhere else, can italicize words, and can make font bigger or smaller, and organize text into blocks and paragraphs.  So on.  For example, this string\n",
    "\n",
    "`My cat is very grumpy`\n",
    "\n",
    "Can be rendered as a paragraph by enclosing it in paragraph tags:\n",
    "\n",
    "`<p>My cat is very grumpy</p>`\n",
    "\n",
    "#### Anatomy of an HTML element\n",
    "Let's explore this paragraph element a bit further.\n",
    "\n",
    "<img src=\"https://mdn.mozillademos.org/files/9347/grumpy-cat-small.png\" width=500>\n",
    "\n",
    "The main parts of our element are:\n",
    "\n",
    "* The opening tag: This consists of the name of the element (in this case, p), wrapped in opening and closing angle brackets. This states where the element begins, or starts to take effect — in this case where the start of the paragraph is.\n",
    "* The closing tag: This is the same as the opening tag, except that it includes a forward slash before the element name. This states where the element ends — in this case where the end of the paragraph is. Failing to include a closing tag is one of the common beginner errors and can lead to strange results.\n",
    "* The content: This is the content of the element, which in this case is just text.\n",
    "* The element: The opening tag plus the closing tag plus the content equals the element.\n",
    "\n",
    "\n",
    "Elements can also have attributes, which look like this:\n",
    "\n",
    "<img src=\"https://mdn.mozillademos.org/files/9345/grumpy-cat-attribute-small.png\" width=500>\n",
    "\n",
    "Attributes contain extra information about the element that you don't want to appear in the actual content. Here, class is the attribute name, and editor-note is the attribute value. The class attribute allows you to give the element an identifier that can be later used to target the element with style information and other things.\n",
    "\n",
    "An attribute should always have:\n",
    "\n",
    "* A space between it and the element name (or the previous attribute, if the element already has one or more attributes).\n",
    "* The attribute name, followed by an equals sign.\n",
    "* Opening and closing quote marks wrapped around the attribute value.  \n",
    "---\n",
    "Run the following command to get the first `div` element with the attribute class of value `chart-row__primary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find('div', class_='chart-row__primary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2\n",
    "\n",
    "__Based on the HTML above, classify each of the following as _tags_ or _attributes_. For example, `p` is an element and `class` is an attribute.__\n",
    "\n",
    "1. `div`\n",
    "2. `a`\n",
    "3. `data-tracklabel`\n",
    "4. `href`\n",
    "5. `span`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "1.\n",
    "2.\n",
    "3.\n",
    "4.\n",
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select HTML elements in Beautiful soup, we use the following syntax:\n",
    "\n",
    "    soup.p # Selects the first p element\n",
    "    soup.h1 # Select the first h1 element\n",
    "\n",
    "We can also use the find method and find_all methods. Run the code below and then replace the expression with `soup.find_all('h1')` to get all of the `h1` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace the code here\n",
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that your code returns a list\n",
    "    \n",
    "    [<h1 class=\"site-header__brand\">\n",
    "    <a class=\"site-header__brand-link\" href=\"/\">\n",
    "    <img alt=\"Billboard\" class=\"site-header__brand-logo\" src=\"/static/frontend/2017_09_18_1748/assets/images/Billboard-white.svg\"/>\n",
    "    <span class=\"site-header__brand-name\">Billboard</span>\n",
    "    </a>\n",
    "    </h1>]\n",
    "    \n",
    "    \n",
    "Note that the `img` tag in your output has an attribute `alt` equal to `\"Billboard\"`. We can extract this attribute from the image tag using the following syntax.\n",
    "\n",
    "    soup.TAG['ATTRIBUTE']\n",
    "    \n",
    "Try running the following to get the value of the attribute `class` for tag h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1.a['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3\n",
    "__Output the value of the attribute `alt` in the first `img` tag from above. Your answer should be Billboard.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finding HTML elements, its hard to translate what is on the screen to raw HTML. Fortunately, modern browsers give you to opportunity to inspect the HTML code of different elements.\n",
    "\n",
    "<img src=\"images/web-inspector.png\" width=\"500px\">\n",
    "\n",
    "To do so, right click on some text in your browser. In the pop-up menu, click inspect. Now when you mouse over things on the web page, you can also see which HTML elements you are hovering over.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 4\n",
    "\n",
    "Did you know you can also edit the HTML with the web inspector and see the results render? This is useful for when an interviewer asks you to meme and you aren't prepared.\n",
    "\n",
    "<img src=\"images/edited.png\" width=\"500px\">\n",
    "\n",
    "__Rename a song or artist and share it with your neighbor. Then fill in the following fields.__\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML Tag Name:\n",
    "Class Name:\n",
    "\n",
    "Parent Tag (the enclosing tag):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've gained some very important skills. ;-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Getting started on homework\n",
    "__Using the web inspector and your ability to navigate Beautiful Soup's documentation, find out how to get the _song name_, _artist name_, and _song rank_ of all 100 songs in `soup`.__ Hint: Try iterating over the results of an appropriate soup.find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Examples of the elements stored as a list:\n",
    "# [1, 'Look What You Made Me Do', 'Taylor Swift']\n",
    "# [2, 'Bodak Yellow (Money Moves)', 'Cardi B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### Useful Words\n",
    "\n",
    "* HTML - Hypertext Markup Language\n",
    "\n",
    "    * tags\n",
    "    * attributes\n",
    "    * elements\n",
    "  \n",
    "  Example: `<tag attribute=\"value\">text</tag>`\n",
    "\n",
    "\n",
    "### Python Workflow\n",
    "```\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = ...\n",
    "r = requests.get(url)\n",
    "\n",
    "# Converts the HTML string into a navigable Python object\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "soup.<TAG_1>.<TAG_2>.<TAG_3>['<ATTRIBUTE_NAME>']\n",
    "```\n",
    "### Example Beautiful Soup Expressions\n",
    "```\n",
    "soup.text\n",
    "soup.a['href']\n",
    "soup.find('div', class_='chart-row__song')\n",
    "soup.find_all('a', href=re.compile('notebooks')) # You can use regex too\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
